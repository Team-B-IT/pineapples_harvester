{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"_Training.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"8wJMle-nvNun","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"c02ddc92-ad16-400b-ad13-054054ebe3eb","executionInfo":{"status":"ok","timestamp":1569571468198,"user_tz":-420,"elapsed":21332,"user":{"displayName":"Kiên Phan Trung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDgWYUcQsnhz6dTA5UpC-O6PVzjdFDpFrOlLhJ9bw=s64","userId":"01116316826405903980"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x5ctFXpUaNeL","colab_type":"code","outputId":"59a871e5-3622-451c-e242-a29c0c21dbb6","executionInfo":{"status":"ok","timestamp":1569571511709,"user_tz":-420,"elapsed":1536,"user":{"displayName":"Kiên Phan Trung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDgWYUcQsnhz6dTA5UpC-O6PVzjdFDpFrOlLhJ9bw=s64","userId":"01116316826405903980"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd drive/My Drive/CNTT/Project/pineapple/keras-yolo3-master"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/CNTT/Project/pineapple/keras-yolo3-master\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JVoRF3vnR5-b","colab_type":"code","outputId":"cee3c13d-6b56-474a-ca52-05e7bdadc03a","executionInfo":{"status":"ok","timestamp":1569571530416,"user_tz":-420,"elapsed":6859,"user":{"displayName":"Kiên Phan Trung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDgWYUcQsnhz6dTA5UpC-O6PVzjdFDpFrOlLhJ9bw=s64","userId":"01116316826405903980"}},"colab":{"base_uri":"https://localhost:8080/","height":241}},"source":["pip install keras==2.1.5"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting keras==2.1.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/65/e4aff762b8696ec0626a6654b1e73b396fcc8b7cc6b98d78a1bc53b85b48/Keras-2.1.5-py2.py3-none-any.whl (334kB)\n","\u001b[K     |████████████████████████████████| 337kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.16.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (3.13)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.12.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.3.1)\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.2.5\n","    Uninstalling Keras-2.2.5:\n","      Successfully uninstalled Keras-2.2.5\n","Successfully installed keras-2.1.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FZeNTt-OYvAF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b096f544-5d9a-42d1-b6d8-f9a46747f203"},"source":["\n","\"\"\"\n","Retrain the YOLO model for your own dataset.\n","\"\"\"\n","\n","import numpy as np\n","import keras.backend as K\n","from keras.layers import Input, Lambda\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","from PIL import ImageFile\n","\n","from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n","from yolo3.utils import get_random_data\n","from tensorboardcolab import *\n","\n","def _main():\n","    annotation_path = 'train.txt'\n","    log_dir = 'logs/001/'\n","    classes_path = 'model_data/pineapple_classes.txt'\n","    anchors_path = 'model_data/yolo_anchors.txt'\n","    class_names = get_classes(classes_path)\n","    num_classes = len(class_names)\n","    anchors = get_anchors(anchors_path)\n","    \n","    input_shape = (416,416) # multiple of 32, hw\n","\n","    is_tiny_version = len(anchors)==6 # default setting\n","    if is_tiny_version:\n","        model = create_tiny_model(input_shape, anchors, num_classes,\n","            freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n","    else:\n","        model = create_model(input_shape, anchors, num_classes,\n","            freeze_body=2, weights_path='logs/000/trained_weights_stage_1.h5') # make sure you know what you freeze\n","\n","    logging = TensorBoard(log_dir=log_dir)\n","    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n","        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n","    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n","\n","    val_split = 0.1\n","    with open(annotation_path) as f:\n","        lines = f.readlines()\n","    np.random.seed(10101)\n","    np.random.shuffle(lines)\n","    np.random.seed(None)\n","    num_val = int(len(lines)*val_split)\n","    num_train = len(lines) - num_val\n","\n","    #TensorBoard\n","    tbc=TensorBoardColab()\n","    \n","    \n","    # Train with frozen layers first, to get a stable loss.\n","    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n","    if False:\n","        model.compile(optimizer=Adam(lr=1e-3), loss={\n","            # use custom yolo_loss Lambda layer.\n","            'yolo_loss': lambda y_true, y_pred: y_pred})\n","\n","        batch_size = 32\n","        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n","        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n","                steps_per_epoch=max(1, num_train//batch_size),\n","                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n","                validation_steps=max(1, num_val//batch_size),\n","                epochs= 50,\n","                initial_epoch=0,\n","                callbacks=[logging, checkpoint, TensorBoardColabCallback(tbc)])\n","        model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n","    \n","    # Unfreeze and continue training, to fine-tune.\n","    # Train longer if the result is not good.\n","    if True:\n","        for i in range(len(model.layers)):\n","            model.layers[i].trainable = True\n","        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n","        print('Unfreeze all of the layers.')\n","\n","        batch_size = 8 # note that more GPU memory is required after unfreezing the body\n","        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n","        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n","            steps_per_epoch=max(1, num_train//batch_size),\n","            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n","            validation_steps=max(1, num_val//batch_size),\n","            epochs= 50,\n","            initial_epoch= 0,\n","            callbacks=[logging, checkpoint, reduce_lr, early_stopping, TensorBoardColabCallback(tbc)])\n","        model.save_weights(log_dir + 'trained_weights_final.h5')\n","    model.save('trained.model')\n","    # Further training if needed.\n","\n","\n","def get_classes(classes_path):\n","    '''loads the classes'''\n","    with open(classes_path) as f:\n","        class_names = f.readlines()\n","    class_names = [c.strip() for c in class_names]\n","    return class_names\n","\n","def get_anchors(anchors_path):\n","    '''loads the anchors from a file'''\n","    with open(anchors_path) as f:\n","        anchors = f.readline()\n","    anchors = [float(x) for x in anchors.split(',')]\n","    return np.array(anchors).reshape(-1, 2)\n","\n","\n","def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n","            weights_path='model_data/yolo_weights.h5'):\n","    '''create the training model'''\n","    K.clear_session() # get a new session\n","    image_input = Input(shape=(None, None, 3))\n","    h, w = input_shape\n","    num_anchors = len(anchors)\n","\n","    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n","        num_anchors//3, num_classes+5)) for l in range(3)]\n","\n","    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n","    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n","\n","    if load_pretrained:\n","        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n","        print('Load weights {}.'.format(weights_path))\n","        if freeze_body in [1, 2]:\n","            # Freeze darknet53 body or freeze all but 3 output layers.\n","            num = (185, len(model_body.layers)-3)[freeze_body-1]\n","            for i in range(num): model_body.layers[i].trainable = False\n","            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n","\n","    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n","        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n","        [*model_body.output, *y_true])\n","    model = Model([model_body.input, *y_true], model_loss)\n","\n","    return model\n","\n","def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n","            weights_path='model_data/tiny_yolo_weights.h5'):\n","    '''create the training model, for Tiny YOLOv3'''\n","    K.clear_session() # get a new session\n","    image_input = Input(shape=(None, None, 3))\n","    h, w = input_shape\n","    num_anchors = len(anchors)\n","\n","    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n","        num_anchors//2, num_classes+5)) for l in range(2)]\n","\n","    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n","    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n","\n","    if load_pretrained:\n","        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n","        print('Load weights {}.'.format(weights_path))\n","        if freeze_body in [1, 2]:\n","            # Freeze the darknet body or freeze all but 2 output layers.\n","            num = (20, len(model_body.layers)-2)[freeze_body-1]\n","            for i in range(num): model_body.layers[i].trainable = False\n","            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n","\n","    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n","        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n","        [*model_body.output, *y_true])\n","    model = Model([model_body.input, *y_true], model_loss)\n","\n","    return model\n","\n","def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n","    '''data generator for fit_generator'''\n","    n = len(annotation_lines)\n","    i = 0\n","    while True:\n","        image_data = []\n","        box_data = []\n","        for b in range(batch_size):\n","            if i==0:\n","                np.random.shuffle(annotation_lines)\n","            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n","            image_data.append(image)\n","            box_data.append(box)\n","            i = (i+1) % n\n","        image_data = np.array(image_data)\n","        box_data = np.array(box_data)\n","        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n","        yield [image_data, *y_true], np.zeros(batch_size)\n","\n","def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n","    n = len(annotation_lines)\n","    if n==0 or batch_size<=0: return None\n","    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n","\n","if __name__ == '__main__':\n","    ImageFile.LOAD_TRUNCATED_IMAGES = True\n","    _main()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Create YOLOv3 model with 9 anchors and 4 classes.\n"],"name":"stdout"}]}]}